# CreditPredictionAlgorithm (CPA)


<img src="./assert/pipline.png" alt="pipeline" width="600" />

**CPA** æ˜¯ä¸€ä¸ªç”¨äº **è´·æ¬¾è¿çº¦é¢„æµ‹** çš„æœºå™¨å­¦ä¹ ç®—æ³•å°è£…å·¥å…·ã€‚  
å®ƒåŸºäº `scikit-learn`ã€`xgboost` ç­‰æ¡†æ¶ï¼Œæ”¯æŒå¤šç§åˆ†ç±»ç®—æ³•ï¼Œæä¾›äº†ç»Ÿä¸€çš„è®­ç»ƒã€ä¿å­˜ã€åŠ è½½å’Œé¢„æµ‹æ¥å£ã€‚  

## âœ¨ åŠŸèƒ½ç‰¹ç‚¹
- è‡ªåŠ¨åŠ è½½è®­ç»ƒé›† & æµ‹è¯•é›†
- è‡ªåŠ¨ç‰¹å¾é€‰æ‹©ï¼ˆ`SelectKBest`ï¼‰
- å°è£…å¤šç§åˆ†ç±»æ¨¡å‹ï¼šXGBoostã€RandomForestã€Logistic Regressionã€SVMï¼ˆå¯æ‰©å±•ï¼‰
- æ”¯æŒäº¤å‰éªŒè¯ã€è¶…å‚æ•°æœç´¢ï¼ˆHyperoptï¼‰
- æ”¯æŒæ¨¡å‹ä¿å­˜ & åŠ è½½ & å‚æ•°æ›´æ–°
- ç»Ÿä¸€æ¥å£ï¼š
  - `train_xxx()` è®­ç»ƒæ¨¡å‹  
  - `save_model()` ä¿å­˜æ¨¡å‹  
  - `load_model()` åŠ è½½æ¨¡å‹ & ä¿®æ”¹å‚æ•°  
  - `predict_test()` åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹  
  - `predict_single()` å•æ ·æœ¬é¢„æµ‹
 

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
pip install 
numpy
pandas
scikit-learn
xgboost
lightgbm
hyperopt
joblib
matplotlib
seaborn
tqdm
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 1. åˆå§‹åŒ– & åŠ è½½æ•°æ®
```python
from src.model import CreditModelPipeline

pipeline = CreditModelPipeline(
    train_path="train.csv",
    test_path="test.csv"
)

pipeline.load_train_data()
```

### 2. è®­ç»ƒ & ä¿å­˜æ¨¡å‹
```python
# XGBoost
xgb_model = pipeline.train_xgb(n_estimators=50, max_depth=6, learning_rate=0.1)
pipeline.save_model(xgb_model, "XGB.model")

# Random Forest
rf_model = pipeline.train_RandomForest_Classifier(n_estimators=100, max_depth=8)
pipeline.save_model(rf_model, "RF.model")

# Logistic Regression
lr_model = pipeline.train_logistic_regression(degree=1, penalty="l2", C=1.0)
pipeline.save_model(lr_model, "LR.model")

# SVM
svm_model = pipeline.train_svm(kernel="linear", C=1.0)
pipeline.save_model(svm_model, "SVM.model")
```
### 3. åŠ è½½ & ä¿®æ”¹å‚æ•°

```python
xgb_loaded = pipeline.load_model("XGB.model", params={"XGBR__n_estimators": 200})
rf_loaded  = pipeline.load_model("RF.model", params={"RF__max_depth": 10})
lr_loaded  = pipeline.load_model("LR.model", params={"LR__C": 0.5})
svm_loaded = pipeline.load_model("SVM.model", params={"SVC__C": 2.0})
```

### 4. é¢„æµ‹æ•°æ®é›†
```python
result_df = pipeline.predict_test(["XGB.model", "RF.model", "LR.model", "SVM.model"])
print(result_df.head())

è¾“å‡ºç¤ºä¾‹ï¼š

id   XGB_PRE   RF_PRE   LR_PRE   SVM_PRE
0  1    0.1234    0.2123   0.5432   0.6543
1  2    0.4321    0.3312   0.6212   0.4890

```

### 5. å•ä¸ªæ ·æœ¬é¢„æµ‹
```python
sample = {
    "loanAmnt": 15000,
    "term": 36,
    "interestRate": 12.5,
    "grade": "B",
    "subGrade": "B3",
    "employmentLength": 10,
    "issueDateDT": 3650,
    # ... å…¶ä»–è®­ç»ƒæ—¶é€‰ä¸­çš„ç‰¹å¾
}

model = pipeline.load_model("XGB.model")
score = pipeline.predict_single(model, sample)
print("å•ä¸ªæ ·æœ¬é¢„æµ‹è¿çº¦æ¦‚ç‡:", score)
```

## ğŸ”§ æ‰©å±•ï¼šæ”¯æŒæ›´å¤šæ¨¡å‹

ä½ å¯ä»¥å¾ˆæ–¹ä¾¿åœ°æ‰©å±•æ–°çš„ç®—æ³•ï¼Œä¾‹å¦‚ **LightGBM**ã€**KNN**ï¼š

```python
def train_lgb(self, **kwargs):
    from lightgbm import LGBMClassifier
    return Pipeline([
        ("scaler", MinMaxScaler()),
        ("LGB", LGBMClassifier(**kwargs))
    ])

def train_knn(self, n_neighbors=5):
    from sklearn.neighbors import KNeighborsClassifier
    return Pipeline([
        ("scaler", MinMaxScaler()),
        ("KNN", KNeighborsClassifier(n_neighbors=n_neighbors))
    ])

# è®­ç»ƒ & ä¿å­˜
lgb_model = pipeline.train_lgb(n_estimators=200, learning_rate=0.05)
pipeline.save_model(lgb_model, "LGB.model")

# é¢„æµ‹æ•´ä¸ªæµ‹è¯•é›†
result_df = pipeline.predict_test(["LGB.model"])
print(result_df.head())

# å•ä¸ªæ ·æœ¬é¢„æµ‹
sample = {
    "loanAmnt": 15000,
    "term": 36,
    "interestRate": 12.5,
    "grade": "B",
    "subGrade": "B3",
    "employmentLength": 10,
    "issueDateDT": 3650,
    # âš ï¸ éœ€åŒ…å«è®­ç»ƒæ—¶é€‰ä¸­çš„æ‰€æœ‰ç‰¹å¾
}

model = pipeline.load_model("LGB.model")
score = pipeline.predict_single(model, sample)
print("å•ä¸ªæ ·æœ¬é¢„æµ‹è¿çº¦æ¦‚ç‡:", score)
```
